{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train-Hin-En.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOEWrKoAl3zlHZsG1axbZx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsniroop/xlm_roberta_NMT/blob/master/Hindi-Fr-Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CEKJzfZtanQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "854a0845-aa46-4121-82b4-9c5f74cd4279"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/pytorch/fairseq.git\n",
        "pip install fairseq\n",
        "\n",
        "cd fairseq\n",
        "pip install fastBPE regex requests sacremoses subword_nmt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fairseq in ./fairseq (0.9.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.4.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.38.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.6.6)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (0.996.5)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (1.7.0)\n",
            "Requirement already satisfied: fastBPE in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.38)\n",
            "Requirement already satisfied: subword_nmt in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.38.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'fairseq' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C6qX8PwtwRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "3116788c-e6e0-4b32-9325-8b2633de3a69"
      },
      "source": [
        "%%bash\n",
        "cd fairseq/\n",
        "\n",
        "pip install --editable ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.18.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.4.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (4.38.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (0.29.16)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.14.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.4.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.9.0) (3.6.6)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.9.0) (0.996.5)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.9.0) (1.7.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.9.0) (2.20)\n",
            "Installing collected packages: fairseq\n",
            "  Found existing installation: fairseq 0.9.0\n",
            "    Uninstalling fairseq-0.9.0:\n",
            "      Successfully uninstalled fairseq-0.9.0\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUhTqxkn4R3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd fairseq/\n",
        "\n",
        "rm -rf data-bin/\n",
        "rm -rf iitb_hi_en/\n",
        "\n",
        "mkdir iitb_hi_en/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrknmi1uvEv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "339784d9-8cbf-4f36-f47d-3d326379e0f5"
      },
      "source": [
        "%%bash\n",
        "cd fairseq/\n",
        "#!/bin/bash\n",
        "# Adapted from https://github.com/facebookresearch/MIXER/blob/master/prepareData.sh\n",
        "\n",
        "echo 'Cloning Moses github repository (for tokenization scripts)...'\n",
        "#git clone https://github.com/moses-smt/mosesdecoder.git\n",
        "\n",
        "echo 'Cloning Subword NMT repository (for BPE pre-processing)...'\n",
        "#git clone https://github.com/rsennrich/subword-nmt.git\n",
        "\n",
        "SCRIPTS=mosesdecoder/scripts\n",
        "TOKENIZER=$SCRIPTS/tokenizer/tokenizer.perl\n",
        "CLEAN=$SCRIPTS/training/clean-corpus-n.perl\n",
        "NORM_PUNC=$SCRIPTS/tokenizer/normalize-punctuation.perl\n",
        "REM_NON_PRINT_CHAR=$SCRIPTS/tokenizer/remove-non-printing-char.perl\n",
        "BPEROOT=subword-nmt/subword_nmt\n",
        "BPE_TOKENS=20000\n",
        "\n",
        "CORPORA=('pruned_train')\n",
        "\n",
        "if [ ! -d \"$SCRIPTS\" ]; then\n",
        "    echo \"Please set SCRIPTS variable correctly to point to Moses scripts.\"\n",
        "    exit\n",
        "fi\n",
        "\n",
        "src=hi\n",
        "tgt=en\n",
        "lang=hi-en\n",
        "prep=iitb_hi_en\n",
        "tmp=$prep/tmp\n",
        "orig=orig\n",
        "\n",
        "mkdir -p $orig $tmp $prep\n",
        "\n",
        "\n",
        "cp hi-en/* $orig/\n",
        "\n",
        "echo \"pre-processing train data...\"\n",
        "for l in $src $tgt; do\n",
        "    #rm $tmp/train.tags.$lang.tok.$l\n",
        "    for f in \"${CORPORA[@]}\"; do\n",
        "        cat $orig/$f.$l | \\\n",
        "            perl $NORM_PUNC $l | \\\n",
        "            perl $REM_NON_PRINT_CHAR | \\\n",
        "            perl $TOKENIZER -threads 8 -a -l $l >> $tmp/train.tags.$lang.tok.$l\n",
        "    done\n",
        "done\n",
        "\n",
        "\n",
        "echo \"splitting train and valid...\"\n",
        "for l in $src $tgt; do\n",
        "    awk '{if (NR%1333 == 0)  print $0;}' $tmp/train.tags.$lang.tok.$l > $tmp/valid.$l\n",
        "    awk '{if (NR%1333 != 0)  print $0;}' $tmp/train.tags.$lang.tok.$l > $tmp/train.$l\n",
        "done\n",
        "\n",
        "\n",
        "TRAIN=$tmp/train.hi-en\n",
        "BPE_CODE=$prep/code\n",
        "rm -f $TRAIN\n",
        "for l in $src $tgt; do\n",
        "    cat $tmp/train.$l >> $TRAIN\n",
        "done\n",
        "\n",
        "echo \"learn_bpe.py on ${TRAIN}...\"\n",
        "python $BPEROOT/learn_bpe.py -s $BPE_TOKENS < $TRAIN > $BPE_CODE\n",
        "\n",
        "for L in $src $tgt; do\n",
        "    for f in train.$L valid.$L; do\n",
        "        echo \"apply_bpe.py to ${f}...\"\n",
        "        python $BPEROOT/apply_bpe.py -c $BPE_CODE < $tmp/$f > $tmp/bpe.$f\n",
        "    done\n",
        "done\n",
        "\n",
        "perl $CLEAN -ratio 1.5 $tmp/bpe.train $src $tgt $prep/train 1 250\n",
        "perl $CLEAN -ratio 1.5 $tmp/bpe.valid $src $tgt $prep/valid 1 250\n",
        "\n",
        "#for L in $src $tgt; do\n",
        "#    cp $tmp/bpe.test.$L $prep/test.$L\n",
        "#done\n",
        "echo 'Done'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "Cloning Subword NMT repository (for BPE pre-processing)...\n",
            "pre-processing train data...\n",
            "splitting train and valid...\n",
            "learn_bpe.py on iitb_hi_en/tmp/train.hi-en...\n",
            "apply_bpe.py to train.hi...\n",
            "apply_bpe.py to valid.hi...\n",
            "apply_bpe.py to train.en...\n",
            "apply_bpe.py to valid.en...\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenizer Version 1.1\n",
            "Language: hi\n",
            "Number of threads: 8\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "clean-corpus.perl: processing iitb_hi_en/tmp/bpe.train.hi & .en to iitb_hi_en/train, cutoff 1-250, ratio 1.5\n",
            "..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)........\n",
            "Input sentences: 787507  Output sentences:  479248\n",
            "clean-corpus.perl: processing iitb_hi_en/tmp/bpe.valid.hi & .en to iitb_hi_en/valid, cutoff 1-250, ratio 1.5\n",
            "\n",
            "Input sentences: 591  Output sentences:  360\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V7Y1x0IyVGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f33ee119-95f5-485b-f9b7-a7892075f653"
      },
      "source": [
        "%%bash\n",
        "cd fairseq/\n",
        "\n",
        "TEXT=iitb_hi_en\n",
        "fairseq-preprocess --source-lang hi --target-lang en \\\n",
        "    --trainpref $TEXT/train --validpref $TEXT/valid \\\n",
        "    --destdir data-bin/iitb_hi_en \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-13 02:29:10 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bpe=None, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iitb_hi_en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='hi', srcdict=None, target_lang='en', task='translation', tensorboard_logdir='', testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='iitb_hi_en/train', user_dir=None, validpref='iitb_hi_en/valid', workers=1)\n",
            "2020-04-13 02:30:42 | INFO | fairseq_cli.preprocess | [hi] Dictionary: 11871 types\n",
            "2020-04-13 02:33:14 | INFO | fairseq_cli.preprocess | [hi] iitb_hi_en/train.hi: 479248 sents, 15225681 tokens, 0.0% replaced by <unk>\n",
            "2020-04-13 02:33:14 | INFO | fairseq_cli.preprocess | [hi] Dictionary: 11871 types\n",
            "2020-04-13 02:33:14 | INFO | fairseq_cli.preprocess | [hi] iitb_hi_en/valid.hi: 360 sents, 11037 tokens, 0.0% replaced by <unk>\n",
            "2020-04-13 02:33:14 | INFO | fairseq_cli.preprocess | [en] Dictionary: 12463 types\n",
            "2020-04-13 02:35:16 | INFO | fairseq_cli.preprocess | [en] iitb_hi_en/train.en: 479248 sents, 12585605 tokens, 0.0% replaced by <unk>\n",
            "2020-04-13 02:35:16 | INFO | fairseq_cli.preprocess | [en] Dictionary: 12463 types\n",
            "2020-04-13 02:35:16 | INFO | fairseq_cli.preprocess | [en] iitb_hi_en/valid.en: 360 sents, 9135 tokens, 0.0219% replaced by <unk>\n",
            "2020-04-13 02:35:16 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/iitb_hi_en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J3K5-uYWc7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd66a9c2-ce2e-4273-a967-04230c4a89e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FANDwRSa2qeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98e3ec7f-da21-42e2-8a01-7578a6c3ba97"
      },
      "source": [
        "!mkdir hi-en-best/\n",
        "!cd fairseq/ && python train.py data-bin/iitb_hi_en --label-smoothing 0.1 --adam-betas '(0.9,0.98)' \\\n",
        "    --optimizer adam -s hi -t en --criterion label_smoothed_cross_entropy --lr 0.0005 --lr-scheduler inverse_sqrt --clip-norm 0.1 --dropout 0.2 --max-tokens 2000 \\\n",
        "    --arch transformer_vaswani_wmt_en_fr_big --save-dir ../hi-en-best --max-epoch 2 | tee -a ../hi-en-best/training.log"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘hi-en-best/’: File exists\n",
            "2020-04-13 04:43:16 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_vaswani_wmt_en_fr_big', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iitb_hi_en', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=2, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=2000, max_tokens_valid=2000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='../hi-en-best', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='hi', target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0)\n",
            "2020-04-13 04:43:16 | INFO | fairseq.tasks.translation | [hi] dictionary: 11872 types\n",
            "2020-04-13 04:43:16 | INFO | fairseq.tasks.translation | [en] dictionary: 12464 types\n",
            "2020-04-13 04:43:16 | INFO | fairseq.data.data_utils | loaded 360 examples from: data-bin/iitb_hi_en/valid.hi-en.hi\n",
            "2020-04-13 04:43:16 | INFO | fairseq.data.data_utils | loaded 360 examples from: data-bin/iitb_hi_en/valid.hi-en.en\n",
            "2020-04-13 04:43:16 | INFO | fairseq.tasks.translation | data-bin/iitb_hi_en valid hi-en 360 examples\n",
            "2020-04-13 04:43:18 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embed_tokens): Embedding(11872, 1024, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embed_tokens): Embedding(12464, 1024, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2020-04-13 04:43:18 | INFO | fairseq_cli.train | model transformer_vaswani_wmt_en_fr_big, criterion LabelSmoothedCrossEntropyCriterion\n",
            "2020-04-13 04:43:18 | INFO | fairseq_cli.train | num. model params: 214040576 (num. trained: 214040576)\n",
            "2020-04-13 04:43:22 | INFO | fairseq_cli.train | training on 1 GPUs\n",
            "2020-04-13 04:43:22 | INFO | fairseq_cli.train | max tokens per GPU = 2000 and max sentences per GPU = None\n",
            "2020-04-13 04:43:55 | INFO | fairseq.trainer | loaded checkpoint ../hi-en-best/checkpoint_last.pt (epoch 1 @ 8755 updates)\n",
            "2020-04-13 04:43:55 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2020-04-13 04:43:56 | INFO | fairseq.data.data_utils | loaded 479248 examples from: data-bin/iitb_hi_en/train.hi-en.hi\n",
            "2020-04-13 04:43:57 | INFO | fairseq.data.data_utils | loaded 479248 examples from: data-bin/iitb_hi_en/train.hi-en.en\n",
            "2020-04-13 04:43:57 | INFO | fairseq.tasks.translation | data-bin/iitb_hi_en train hi-en 479248 examples\n",
            "epoch 002: 100% 8754/8755 [1:47:45<00:00,  1.37it/s, loss=7.148, nll_loss=6.128, ppl=69.95, wps=1928, ups=1.34, wpb=1436.9, bsz=51.3, num_updates=17500, lr=0.000239046, gnorm=9.418, clip=100, train_wall=74, wall=0]\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  11% 1/9 [00:00<00:02,  2.92it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  22% 2/9 [00:00<00:02,  3.30it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  33% 3/9 [00:00<00:01,  3.56it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  44% 4/9 [00:00<00:01,  4.05it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  56% 5/9 [00:01<00:00,  4.19it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  67% 6/9 [00:01<00:00,  4.20it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  78% 7/9 [00:01<00:00,  4.30it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset: 100% 9/9 [00:01<00:00,  4.83it/s]\u001b[A\n",
            "epoch 002: 100% 8754/8755 [1:47:48<00:00,  1.37it/s, loss=7.148, nll_loss=6.128, ppl=69.95, wps=1928, ups=1.34, wpb=1436.9, bsz=51.3, num_updates=17500, lr=0.000239046, gnorm=9.418, clip=100, train_wall=74, wall=0]epoch 002 | valid on 'valid' subset | loss 7.38 | nll_loss 6.305 | ppl 79.06 | wps 4418.1 | wpb 1015 | bsz 40 | num_updates 17510 | best_loss 7.38\n",
            "2020-04-13 06:34:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../hi-en-best/checkpoint2.pt (epoch 2 @ 17510 updates, score 7.38) (writing took 163.38972638900123 seconds)\n",
            "epoch 002 | loss 7.879 | nll_loss 6.963 | ppl 124.72 | wps 1916.9 | ups 1.33 | wpb 1437.5 | bsz 54.7 | num_updates 17510 | lr 0.000238977 | gnorm 4.664 | clip 100 | train_wall 12877 | wall 0\n",
            "2020-04-13 06:34:38 | INFO | fairseq_cli.train | done training in 6636.9 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPMny_U5IHdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd fairseq/ && python interactive.py data-bin/iitb_hi_en/ --path $SAVE_PATH --bpe subword_nmt  --bpe-codes iitb_hi_en/code --buffer-size 1 --beam 6 --lenpen 0.6 --tokenizer moses -s hi -t en --remove-bpe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymTwNs-cNtgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd fairseq/ && python generate.py \\\n",
        "    data-bin/iitb_hi_en/ \\\n",
        "    --path checkpoints/hi_en1000/checkpoint5.pt \\\n",
        "    --beam 5 --remove-bpe=subword_nmt -s hi -t en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbpYdwkxRVXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC9VrfPXDk6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8ba88655-f3a4-44a2-caf7-9f2efcccd359"
      },
      "source": [
        "import os\n",
        "!pwd\n",
        "os.chdir('/content/')\n",
        "!pwd\n",
        "from fairseq.models.transformer import TransformerModel\n",
        "from fairseq.models import FairseqEncoderDecoderModel\n",
        "\n",
        "hi2en = TransformerModel.from_pretrained(\n",
        "  '/content/hi-en-best/',\n",
        "  checkpoint_file='checkpoint2.pt',\n",
        "  data_name_or_path='/content/fairseq/data-bin/iitb_hi_en',\n",
        "  bpe='subword_nmt',\n",
        "  bpe_codes='/content/fairseq/iitb_hi_en/code')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYCsBi_eU-T4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74f0a3b0-1732-46c0-c56d-2de79257bc39"
      },
      "source": [
        "hi2en.translate('वे लोग क्यों भाग गए ?')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What are the people ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ArghNy09JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp hi-en-best/checkpoint2.pt gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD7IQMBLUHdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4ba0289f-22e8-46f7-9fbc-39d4dfc37bf3"
      },
      "source": [
        "en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n",
            "100%|██████████| 2316140317/2316140317 [03:14<00:00, 11916792.15B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRKtPHBAY0_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fairseq.hub_utils import GeneratorHubInterface\n",
        "from fairseq.tasks.translation import TranslationTask\n",
        "\n",
        "hi2en_encoder = list(hi2en.models[0].children())[0]\n",
        "en2fr_decoder = list(en2fr.models[0].children())[1]\n",
        "\n",
        "class hi_fr_translator(FairseqEncoderDecoderModel):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__(encoder, decoder)\n",
        "\n",
        "class hi_fr_task(TranslationTask):\n",
        "  def __init__(self, args, src_dict, tgt_dict):\n",
        "    super().__init__(args, src_dict, tgt_dict)\n",
        "\n",
        "hi2fr_task = hi_fr_task(en2fr.args, hi2en.task.source_dictionary, en2fr.task.target_dictionary)\n",
        "\n",
        "hi2fr = hi_fr_translator(hi2en_encoder, en2fr_decoder)\n",
        "gen_obj = GeneratorHubInterface(en2fr.args, hi2fr_task, [hi2fr])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhz1oGMRZh24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "547eccbd-4647-4453-e9bf-ea24b2f02286"
      },
      "source": [
        "fr = gen_obj.translate('वे लोग क्यों भाग गए ?', beam=5)\n",
        "print(fr)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L'un des objectifs de la stratégie est d'être présent dans l'un des objectifs de la stratégie et de la stratégie.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}